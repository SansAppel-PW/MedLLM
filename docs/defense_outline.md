# 硕士答辩提纲（MedLLM）

## 1. 研究背景与问题定义
- 医疗大模型在问答场景中存在“事实性幻觉”与“高风险误导”问题。
- 目标：构建一条可复现工程链路，同时提升事实一致性与安全拦截能力。

## 2. 研究目标与贡献
- 贡献一：基于真实数据源构建训练集与评测集（含许可登记与版本化）。
- 贡献二：提出白盒不确定性 + 检索核查 + 风险融合的混合检测框架。
- 贡献三：完成 SFT / DPO / SimPO 工程流水线与可复现实验报告。
- 贡献四：形成论文资产库（表格、错误案例、流程图、对比结果）。

## 3. 方法设计
- 数据治理：Schema 统一、PII 清洗、KG 映射、冲突校验。
- 风险检测：事实抽取、证据检索、NLI 判定、风险分级与拦截。
- 对齐训练：SFT 基座 + 偏好对构造 + DPO/SimPO 对比。

## 4. 实验设置
- 真实训练集：19,978（去重后），train/dev/test = 15,984/1,997/1,997。
- 真实评测集：real_medqa_benchmark 3,600 条（正负配对）。
- 关键指标：Accuracy、Precision、Recall、F1、Unsafe Pass Rate、Interception Rate。

## 5. 核心结果（答辩重点）
- 混合检测在真实评测集上达成高准确率（见 `reports/detection_eval.md`）。
- 检测消融显示：检索核查与混合策略显著优于仅白盒策略。
- 对标代理实验：MedLLM-Hybrid 在安全放行率上显著优于 raw baseline。

## 6. 错误分析与局限
- Top30 失败案例见 `reports/error_analysis.md` 与 `reports/thesis_assets/cases/`。
- 主要问题：选项类样本中的错配模式、复杂语义边界样本。
- 局限：当前对标为“代理复现实验”，非官方模型完整推理复现。

## 7. 后续工作
- 引入真实开源模型批量推理，完成严格同口径 SOTA 复现。
- 扩展中文临床长文本场景，加入时序病程与多轮对话评测。
- 联合人工标注专家开展误判复核与阈值校准。
