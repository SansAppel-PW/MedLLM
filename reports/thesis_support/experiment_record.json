{
  "git_commit": "UNKNOWN",
  "dataset": {},
  "training_status": {
    "sft": "real",
    "dpo": "real",
    "simpo": "real",
    "kto": "real"
  },
  "resource": {
    "created_at_utc": "2026-02-27T20:18:21.373302+00:00",
    "platform": "Linux-5.4.0-136-generic-x86_64-with-glibc2.35",
    "accelerator": "cuda",
    "cuda_device_count": 1,
    "cuda_total_mem_gb": 31.73,
    "cuda_devices": [
      {
        "index": 0,
        "name": "Tesla V100-PCIE-32GB",
        "mem_gb": 31.73,
        "compute_capability": "7.0"
      }
    ],
    "cuda_min_compute_capability_major": 7
  },
  "artifact_report": {
    "benchmark": "data/benchmark/real_medqa_benchmark.jsonl",
    "splits": [
      "test",
      "validation"
    ],
    "samples": 1200,
    "by_risk": {
      "low": {
        "count": 600,
        "prefix_rate": 1.0,
        "option_letter_rate": 1.0
      },
      "high": {
        "count": 600,
        "prefix_rate": 1.0,
        "option_letter_rate": 0.008333333333333333
      },
      "medium": {
        "count": 0,
        "prefix_rate": 0.0,
        "option_letter_rate": 0.0
      }
    },
    "option_letter_gap_low_high": 0.9916666666666667,
    "artifact_leakage_risk": "HIGH"
  },
  "artifact_report_v2": {
    "benchmark": "data/benchmark/real_medqa_benchmark_v2_balanced.jsonl",
    "splits": [
      "test",
      "validation"
    ],
    "samples": 1200,
    "by_risk": {
      "low": {
        "count": 600,
        "prefix_rate": 1.0,
        "option_letter_rate": 1.0
      },
      "high": {
        "count": 600,
        "prefix_rate": 1.0,
        "option_letter_rate": 1.0
      },
      "medium": {
        "count": 0,
        "prefix_rate": 0.0,
        "option_letter_rate": 0.0
      }
    },
    "option_letter_gap_low_high": 0.0,
    "artifact_leakage_risk": "LOW"
  },
  "detection_v2": {
    "accuracy": 0.5,
    "precision": 0.0,
    "recall": 0.0,
    "f1": 0.0
  },
  "detection_llm_judge": {
    "accuracy": 0.7333,
    "precision": 0.6892,
    "recall": 0.85,
    "f1": 0.7612
  },
  "detection_v2_hybrid_llm": {
    "accuracy": 0.6075,
    "precision": 0.7087,
    "recall": 0.365,
    "f1": 0.4818
  },
  "detection_v2_hybrid_impact": {
    "samples": 1200,
    "llm_used": 500,
    "llm_promotions": 309,
    "rule_only": {
      "variant": "rule_only",
      "accuracy": 0.5,
      "precision": 0.0,
      "recall": 0.0,
      "f1": 0.0,
      "specificity": 1.0,
      "fpr": 0.0,
      "fnr": 1.0,
      "tp": 0,
      "fp": 0,
      "tn": 600,
      "fn": 600,
      "sample_count": 1200
    },
    "hybrid": {
      "variant": "hybrid_with_llm",
      "accuracy": 0.6075,
      "precision": 0.708738,
      "recall": 0.365,
      "f1": 0.481848,
      "specificity": 0.85,
      "fpr": 0.15,
      "fnr": 0.635,
      "tp": 219,
      "fp": 90,
      "tn": 510,
      "fn": 381,
      "sample_count": 1200
    },
    "delta": {
      "accuracy": 0.10750000000000004,
      "precision": 0.7087378640776699,
      "recall": 0.365,
      "f1": 0.4818481848184819,
      "specificity": -0.15000000000000002,
      "fpr": 0.15,
      "fnr": -0.365
    }
  },
  "eval_rows": [
    {
      "model": "SFT",
      "factscore": "0.5000",
      "utility": "1.0000",
      "risk_score": "0.2735",
      "interception_rate": "1.0000"
    },
    {
      "model": "DPO",
      "factscore": "0.5000",
      "utility": "0.8429",
      "risk_score": "0.2782",
      "interception_rate": "1.0000"
    },
    {
      "model": "SimPO",
      "factscore": "0.5000",
      "utility": "0.8429",
      "risk_score": "0.2782",
      "interception_rate": "1.0000"
    }
  ],
  "sota_top4": [
    {
      "name": "MedLLM-Hybrid (ours)",
      "accuracy": "1.0",
      "precision": "1.0",
      "recall": "1.0",
      "f1": "1.0",
      "specificity": "1.0",
      "unsafe_pass_rate": "0.0",
      "risky_block_rate": "0.0",
      "tp": "400.0",
      "fp": "0.0",
      "tn": "400.0",
      "fn": "0.0"
    },
    {
      "name": "BioMistral-7B-Proxy (whitebox)",
      "accuracy": "0.36625",
      "precision": "0.39731285988483683",
      "recall": "0.5175",
      "f1": "0.4495114006514657",
      "specificity": "0.215",
      "unsafe_pass_rate": "0.4825",
      "risky_block_rate": "0.1875",
      "tp": "207.0",
      "fp": "314.0",
      "tn": "86.0",
      "fn": "193.0"
    },
    {
      "name": "HuatuoGPT-7B-Proxy (raw)",
      "accuracy": "0.5",
      "precision": "0.0",
      "recall": "0.0",
      "f1": "0.0",
      "specificity": "1.0",
      "unsafe_pass_rate": "1.0",
      "risky_block_rate": "0.0",
      "tp": "0.0",
      "fp": "0.0",
      "tn": "400.0",
      "fn": "400.0"
    },
    {
      "name": "MedQA-RAG-Proxy (retrieval)",
      "accuracy": "0.5",
      "precision": "0.0",
      "recall": "0.0",
      "f1": "0.0",
      "specificity": "1.0",
      "unsafe_pass_rate": "1.0",
      "risky_block_rate": "0.0",
      "tp": "0.0",
      "fp": "0.0",
      "tn": "400.0",
      "fn": "400.0"
    }
  ],
  "error_summary": [
    "- 主预测文件样本数: 1200",
    "- 误判总数: 507",
    "- 漏检数: 193",
    "- 误报数: 314",
    "- BioMistral-7B-Proxy_(whitebox): 507",
    "- 选项类样本检索噪声: 312",
    "- 选项错配未识别: 193",
    "- 长答案熵值偏高: 1"
  ]
}