{
  "git_commit": "d665697535930366a7e9580642b4dbd84daa17bd",
  "dataset": {
    "sources": [
      {
        "name": "cmtmedqa",
        "dataset": "Suprit/CMtMedQA",
        "config": "default",
        "split": "train",
        "num_rows_total": 8000,
        "start_offset": 0,
        "target_count": 8000,
        "fetched_count": 8000,
        "license": "MIT"
      },
      {
        "name": "huatuo26m_lite",
        "dataset": "FreedomIntelligence/Huatuo26M-Lite",
        "config": "default",
        "split": "train",
        "num_rows_total": 6000,
        "start_offset": 0,
        "target_count": 6000,
        "fetched_count": 6000,
        "license": "Apache-2.0"
      },
      {
        "name": "huatuo_encyclopedia",
        "dataset": "FreedomIntelligence/huatuo_encyclopedia_qa",
        "config": "default",
        "split": "train",
        "num_rows_total": 6000,
        "start_offset": 0,
        "target_count": 6000,
        "fetched_count": 6000,
        "license": "Apache-2.0"
      }
    ],
    "merged_before_dedup": 20000,
    "merged_after_dedup": 19978,
    "train_count": 15984,
    "dev_count": 1997,
    "test_count": 1997,
    "benchmark_count": 3600,
    "seed": 42,
    "rebuilt_from_local_artifacts": true
  },
  "training_status": {
    "sft": "real",
    "dpo": "real",
    "simpo": "real",
    "kto": "real"
  },
  "resource": {
    "created_at_utc": "2026-02-27T20:18:21.373302+00:00",
    "platform": "Linux-5.4.0-136-generic-x86_64-with-glibc2.35",
    "accelerator": "cuda",
    "cuda_device_count": 1,
    "cuda_total_mem_gb": 31.73,
    "cuda_devices": [
      {
        "index": 0,
        "name": "Tesla V100-PCIE-32GB",
        "mem_gb": 31.73,
        "compute_capability": "7.0"
      }
    ],
    "cuda_min_compute_capability_major": 7
  },
  "artifact_report": {
    "benchmark": "data/benchmark/real_medqa_benchmark_v2_balanced.jsonl",
    "splits": [
      "test",
      "validation"
    ],
    "samples": 1200,
    "by_risk": {
      "low": {
        "count": 600,
        "prefix_rate": 1.0,
        "option_letter_rate": 1.0
      },
      "high": {
        "count": 600,
        "prefix_rate": 1.0,
        "option_letter_rate": 1.0
      },
      "medium": {
        "count": 0,
        "prefix_rate": 0.0,
        "option_letter_rate": 0.0
      }
    },
    "option_letter_gap_low_high": 0.0,
    "artifact_leakage_risk": "LOW"
  },
  "artifact_report_v2": {
    "benchmark": "data/benchmark/real_medqa_benchmark_v2_balanced.jsonl",
    "splits": [
      "test",
      "validation"
    ],
    "samples": 1200,
    "by_risk": {
      "low": {
        "count": 600,
        "prefix_rate": 1.0,
        "option_letter_rate": 1.0
      },
      "high": {
        "count": 600,
        "prefix_rate": 1.0,
        "option_letter_rate": 1.0
      },
      "medium": {
        "count": 0,
        "prefix_rate": 0.0,
        "option_letter_rate": 0.0
      }
    },
    "option_letter_gap_low_high": 0.0,
    "artifact_leakage_risk": "LOW"
  },
  "detection_v2": {
    "accuracy": 0.5,
    "precision": 0.0,
    "recall": 0.0,
    "f1": 0.0
  },
  "detection_llm_judge": {
    "accuracy": 0.7333,
    "precision": 0.6892,
    "recall": 0.85,
    "f1": 0.7612
  },
  "detection_v2_hybrid_llm": {
    "accuracy": 0.6075,
    "precision": 0.7087,
    "recall": 0.365,
    "f1": 0.4818
  },
  "detection_v2_hybrid_impact": {
    "samples": 1200,
    "llm_used": 500,
    "llm_promotions": 309,
    "rule_only": {
      "variant": "rule_only",
      "accuracy": 0.5,
      "precision": 0.0,
      "recall": 0.0,
      "f1": 0.0,
      "specificity": 1.0,
      "fpr": 0.0,
      "fnr": 1.0,
      "tp": 0,
      "fp": 0,
      "tn": 600,
      "fn": 600,
      "sample_count": 1200
    },
    "hybrid": {
      "variant": "hybrid_with_llm",
      "accuracy": 0.6075,
      "precision": 0.708738,
      "recall": 0.365,
      "f1": 0.481848,
      "specificity": 0.85,
      "fpr": 0.15,
      "fnr": 0.635,
      "tp": 219,
      "fp": 90,
      "tn": 510,
      "fn": 381,
      "sample_count": 1200
    },
    "delta": {
      "accuracy": 0.10750000000000004,
      "precision": 0.7087378640776699,
      "recall": 0.365,
      "f1": 0.4818481848184819,
      "specificity": -0.15000000000000002,
      "fpr": 0.15,
      "fnr": -0.365
    }
  },
  "eval_rows": [
    {
      "model": "SFT",
      "factscore": "0.4971",
      "utility": "1.0000",
      "risk_score": "0.1008",
      "interception_rate": "0.0050"
    },
    {
      "model": "DPO",
      "factscore": "0.4971",
      "utility": "0.8615",
      "risk_score": "0.1102",
      "interception_rate": "0.0050"
    },
    {
      "model": "SimPO",
      "factscore": "0.4971",
      "utility": "0.8615",
      "risk_score": "0.1102",
      "interception_rate": "0.0050"
    }
  ],
  "sota_top4": [
    {
      "name": "BioMistral-7B-Proxy (whitebox)",
      "accuracy": "0.49083333333333334",
      "precision": "0.49411764705882355",
      "recall": "0.77",
      "f1": "0.6019543973941368",
      "specificity": "0.21166666666666667",
      "unsafe_pass_rate": "0.23",
      "risky_block_rate": "0.23166666666666666",
      "balanced_score": "0.47250000000000003",
      "tp": "462.0",
      "fp": "473.0",
      "tn": "127.0",
      "fn": "138.0"
    },
    {
      "name": "MedLLM-Hybrid (ours)",
      "accuracy": "0.6075",
      "precision": "0.7087378640776699",
      "recall": "0.365",
      "f1": "0.4818481848184819",
      "specificity": "0.85",
      "unsafe_pass_rate": "0.635",
      "risky_block_rate": "0.24166666666666667",
      "balanced_score": "0.8225",
      "tp": "219.0",
      "fp": "90.0",
      "tn": "510.0",
      "fn": "381.0"
    },
    {
      "name": "MedQA-RAG-Proxy (retrieval)",
      "accuracy": "0.49916666666666665",
      "precision": "0.42857142857142855",
      "recall": "0.005",
      "f1": "0.009884678747940693",
      "specificity": "0.9933333333333333",
      "unsafe_pass_rate": "0.995",
      "risky_block_rate": "0.005",
      "balanced_score": "0.49749999999999994",
      "tp": "3.0",
      "fp": "4.0",
      "tn": "596.0",
      "fn": "597.0"
    },
    {
      "name": "HuatuoGPT-7B-Proxy (raw)",
      "accuracy": "0.5",
      "precision": "0.0",
      "recall": "0.0",
      "f1": "0.0",
      "specificity": "1.0",
      "unsafe_pass_rate": "1.0",
      "risky_block_rate": "0.0",
      "balanced_score": "0.5",
      "tp": "0.0",
      "fp": "0.0",
      "tn": "600.0",
      "fn": "600.0"
    }
  ],
  "error_summary": [
    "- 主预测文件样本数: 1200",
    "- 误判总数: 601",
    "- 漏检数: 597",
    "- 误报数: 4",
    "- medllm_hybrid: 601",
    "- 选项错配未识别: 597",
    "- 选项类样本检索噪声: 4"
  ]
}